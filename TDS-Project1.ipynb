{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9235,
     "status": "ok",
     "timestamp": 1729716750481,
     "user": {
      "displayName": "Raji",
      "userId": "15359009113822535956"
     },
     "user_tz": -60
    },
    "id": "GtugS3HQZpaj",
    "outputId": "d3e07a82-7b9c-4ab6-eea3-f5c275df7584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1730319135057,
     "user": {
      "displayName": "Raji",
      "userId": "15359009113822535956"
     },
     "user_tz": 0
    },
    "id": "bIM6A9fRWajj",
    "outputId": "26c4bc54-c43b-40b1-f7a4-c05e89f619db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   109  100   109    0     0    654      0 --:--:-- --:--:-- --:--:--   656\n",
      "{\n",
      "  \"message\": \"Bad credentials\",\n",
      "  \"documentation_url\": \"https://docs.github.com/rest\",\n",
      "  \"status\": \"401\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -H \"Authorization: token *personal-access-token-from-github*\" \\\n",
    "\"https://api.github.com/search/users?q=location:Hyderabad+followers:>50?per_page=100\" \\\n",
    "-o users.json\n",
    "\n",
    "!curl -L \\\n",
    "  -H \"Accept: application/vnd.github+json\" \\\n",
    "  -H \"Authorization: Bearer *personal-access-token-from-github*\" \\\n",
    "  \"https://api.github.com/search/users?q=location:Hyderabad+followers:>50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "by1lRkDnE5h4"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "GITHUB_TOKEN =  '*personal-access-token-from-github*'\n",
    "HEADERS = {'Authorization': f\"token {GITHUB_TOKEN}\",\n",
    "           \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "BASE_URL = \"https://api.github.com/rate_limit\"\n",
    "response = requests.get(BASE_URL, headers=HEADERS)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADeSaIAaizNM"
   },
   "source": [
    "**TDS Project 1 - Process the files before answering the assignment questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7746,
     "status": "ok",
     "timestamp": 1729966954568,
     "user": {
      "displayName": "Raji",
      "userId": "15359009113822535956"
     },
     "user_tz": -60
    },
    "id": "nTjO0ZwPbjpO",
    "outputId": "018c5d0e-27f4-4229-994b-c3331e115924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users found: 505\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Example endpoint to get user data from Hyderabad with more than 50 followers\n",
    "GITHUB_TOKEN =  '*personal-access-token-from-github*'\n",
    "HEADERS = {'Authorization': f\"token {GITHUB_TOKEN}\",\n",
    "           \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "BASE_URL = \"https://api.github.com\"\n",
    "location = \"Hyderabad\"\n",
    "min_followers = 50\n",
    "cur_page = 1\n",
    "all_users = []\n",
    "\n",
    "while True:\n",
    "  search_url = f\"{BASE_URL}/search/users?q=location:{location}+followers:>{min_followers}&per_page=100&page={cur_page}\"\n",
    "  response = requests.get(search_url, headers=HEADERS)\n",
    "  print(response.json())\n",
    "\n",
    "  if response.status_code!=200:\n",
    "    print(f\"Error fetching page {cur_page}: {response.status_code}\")\n",
    "\n",
    "  else:\n",
    "    data = response.json()\n",
    "    users = data['items']\n",
    "    print(users)\n",
    "\n",
    "    if not users:\n",
    "      break\n",
    "    all_users.extend(users)\n",
    "    if len(users) < 100:\n",
    "      break\n",
    "\n",
    "    time.sleep(1)\n",
    "    cur_page += 1\n",
    "\n",
    "if len(all_users) > 0:\n",
    "  print(f\"Total users found: {len(all_users)}\")\n",
    "  df = pd.DataFrame(all_users)\n",
    "  df.to_csv('users.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpvNTYLaBC0s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Example endpoint to get user data from Hyderabad with more than 50 followers\n",
    "GITHUB_TOKEN =  '*personal-access-token-from-github*'\n",
    "HEADERS = {'Authorization': f\"token {GITHUB_TOKEN}\",\n",
    "           \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "\n",
    "BASE_URL = \"https://api.github.com\"\n",
    "\n",
    "df = pd.read_csv('users.csv')\n",
    "\n",
    "for user in df['login']:\n",
    "  cur_user = user\n",
    "\n",
    "search_url = f\"{BASE_URL}/users/{cur_user}/repos?per_page=1&page=1\"\n",
    "response = requests.get(search_url, headers=HEADERS)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_490L25FQXn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Example endpoint to get user data from Hyderabad with more than 50 followers\n",
    "GITHUB_TOKEN =  '*personal-access-token-from-github*'\n",
    "HEADERS = {'Authorization': f\"token {GITHUB_TOKEN}\",\n",
    "           \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "BASE_URL = \"https://api.github.com\"\n",
    "count_per_page = 100\n",
    "current_page = 1\n",
    "all_repos = []\n",
    "\n",
    "df = pd.read_csv('users.csv')\n",
    "\n",
    "#for user in range(min(5, len(df['login']))):\n",
    "  #print(\"User: \",df['login'].iloc[user])\n",
    "\n",
    "for user in df['login']:\n",
    "  print(user)\n",
    "  cur_user = user\n",
    "\n",
    "  while True:\n",
    "   search_url = f\"{BASE_URL}/users/{cur_user}/repos?per_page={count_per_page}&page={current_page}\"\n",
    "   response = requests.get(search_url, headers=HEADERS)\n",
    "\n",
    "   if response.status_code != 200:\n",
    "    print(f\"Error fetching page {current_page}: {response.status_code}\")\n",
    "\n",
    "   repos = response.json()\n",
    "   if(len(repos) > 0):\n",
    "    all_repos.extend(repos)\n",
    "\n",
    "   if(len(repos) < count_per_page):\n",
    "    break\n",
    "   else:\n",
    "    time.sleep(0.1)\n",
    "    current_page += 1\n",
    "\n",
    "print(f\"Total repos found: {len(all_repos)}\")\n",
    "if all_repos:\n",
    "  df = pd.DataFrame(all_repos)\n",
    "  df.to_csv('repositories.csv', index=False)\n",
    "else:\n",
    "  print(\"No repositories found to create a DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnR5RitBNJqp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Example endpoint to get user data from Hyderabad with more than 50 followers\n",
    "GITHUB_TOKEN =  '*personal-access-token-from-github*'\n",
    "HEADERS = {'Authorization': f\"token {GITHUB_TOKEN}\",\n",
    "           \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}\n",
    "\n",
    "BASE_URL = \"https://api.github.com\"\n",
    "df = pd.read_csv('users.csv')\n",
    "final_users = []\n",
    "\n",
    "for user in df['login']:\n",
    "  cur_user = user\n",
    "\n",
    "  search_url = f\"{BASE_URL}/users/{cur_user}\"\n",
    "  response = requests.get(search_url, headers=HEADERS)\n",
    "  user_data = response.json()\n",
    "\n",
    "  #Extract the fields you need - login,name,company,location,email,hireable,bio,public_repos,followers,following,created_at:\n",
    "  # cleaned_data = {\n",
    "  #     'login': user_data['login'],\n",
    "  #     'name': user_data['name'],\n",
    "  #     'company': user_data['company']\n",
    "  # }\n",
    "\n",
    "  final_users.append(user_data)\n",
    "\n",
    "print(final_users)\n",
    "\n",
    "df = pd.DataFrame(final_users)\n",
    "df.to_csv('user_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CA63W9r19Cp"
   },
   "source": [
    "**USERS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZgpgQLtVHGr"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# URL to access the raw CSV file directly\n",
    "url_users = \"https://raw.githubusercontent.com/Rajalakshmi12/IITM_Tds_Project1/main/users.csv\"\n",
    "url_repos = \"https://raw.githubusercontent.com/Rajalakshmi12/IITM_Tds_Project1/main/repositories.csv\"\n",
    "\n",
    "#Q1,Q2,Q4 Make the request to get the CSV file content\n",
    "response = requests.get(url_users)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Read the CSV content into a pandas DataFrame\n",
    "    csv_content = response.content.decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_content))\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], utc=True)\n",
    "\n",
    "    #Q1. Top 5 users\n",
    "    df.index = df.index + 1\n",
    "    df_sorted1 = df.sort_values(by=\"followers\", ascending=False)\n",
    "    #print(df_sorted1['login'].head(5))\n",
    "\n",
    "    #Q2. Top 5 early registered Users\n",
    "    df_sorted2 = df.sort_values(by=\"created_at\", ascending=True)\n",
    "    #print(df_sorted2[['login']].head(5))\n",
    "\n",
    "    #Q4. Top company these developers work at, group by company and sort by count in desc order\n",
    "    grouped_df4 = df.groupby('company').size().reset_index(name='count')\n",
    "    df_sorted4 = grouped_df4.sort_values(by=\"count\", ascending=False)\n",
    "    #print(df_sorted4)\n",
    "\n",
    "    #Q6. Get the users joined after 2020, then get the second most popular language\n",
    "    df['login'] = df['login'].str.strip()\n",
    "    target_datetime = pd.Timestamp('2019-12-31 23:59:59+00:00',tz='UTC')\n",
    "    df_filt6 = df[df['created_at'] > target_datetime]\n",
    "    usernames = df_filt6['login'].tolist()\n",
    "    #Get the list of usernames from the filtered list\n",
    "    print(\"Length of usernames: \",len(usernames))\n",
    "\n",
    "    #80 users repositories languages required, so get the login id and filter the data\n",
    "    response_from_repos = requests.get(url_repos)\n",
    "\n",
    "    if response_from_repos.status_code == 200:\n",
    "      # Read the CSV content into a pandas DataFrame\n",
    "      csv_content = response_from_repos.content.decode('utf-8')\n",
    "      df_repo = pd.read_csv(StringIO(csv_content))\n",
    "      df_repo['login'] = df_repo['login'].str.strip()\n",
    "\n",
    "      for user in usernames:\n",
    "        df_repofilt_temp = df_repo[df_repo['login'] == user]\n",
    "        if not df_repofilt_temp.empty:\n",
    "          print(f\"User '{user}' found:\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAwxPQ8I2AT8"
   },
   "source": [
    "**REPOSITORIES:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-l-EITi-iuKM"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "#Q3 Make the request to get the CSV file content\n",
    "url_repos = \"https://raw.githubusercontent.com/Rajalakshmi12/IITM_Tds_Project1/main/repositories.csv\"\n",
    "response = requests.get(url_repos)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Read the CSV content into a pandas DataFrame\n",
    "    csv_content = response.content.decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_content))\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df = df.dropna(subset=['license_name'])\n",
    "    df.index = df.index + 1\n",
    "\n",
    "\n",
    "    #Q3 Top 3 most popular license --> Sort count by Descending order\n",
    "    #Group by code\n",
    "    grouped_df3 = df.groupby('license_name').size().reset_index(name='count')\n",
    "    df_sorted3 = grouped_df3.sort_values(by='count', ascending=False)\n",
    "    #print(df_sorted3)\n",
    "\n",
    "    #Q5 Most popular programming language\n",
    "    #Group by Language\n",
    "    grouped_df5 = df.groupby('language').size().reset_index(name='count')\n",
    "    df_sorted5 = grouped_df5.sort_values(by='count', ascending=False)\n",
    "    #print(df_sorted5)\n",
    "\n",
    "    df = df.dropna(subset=['language'])\n",
    "\n",
    "    #Q7.Which language has the highest average number of stars per repository?\n",
    "    #Group by Programming Language\n",
    "    #Collect all the starts count and find the average\n",
    "    grouped_df7 = df.groupby('language')['stargazers_count'].mean().reset_index(name='average_count')\n",
    "\n",
    "    #Sort by average count\n",
    "    df_sorted7 = grouped_df7.sort_values(by='average_count', ascending=False)\n",
    "    print(df_sorted7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1730153916062,
     "user": {
      "displayName": "Raji",
      "userId": "15359009113822535956"
     },
     "user_tz": 0
    },
    "id": "DJnNrzjmMmkw",
    "outputId": "1eb454c5-6f5f-4ccd-cd3e-cae064135639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            login  count\n",
      "2      anjijava16     78\n",
      "1    Shekharrajak     76\n",
      "3       arvindr21     68\n",
      "6     in28minutes     25\n",
      "7    maddydevgits     25\n",
      "0      MadhavBahl     13\n",
      "5  iam-veeramalla      6\n",
      "4   ashokitschool      5\n",
      "Correlation coefficient between followers and total repositories: 0.22979333250595757\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "#Q3 Make the request to get the CSV file content\n",
    "url_users = \"https://raw.githubusercontent.com/Rajalakshmi12/IITM_Tds_Project1/main/users.csv\"\n",
    "url_repos = \"https://raw.githubusercontent.com/Rajalakshmi12/IITM_Tds_Project1/main/repositories.csv\"\n",
    "response = requests.get(url_repos)\n",
    "response_users = requests.get(url_users)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Read the CSV (Repos) content into a pandas DataFrame\n",
    "    csv_content = response.content.decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_content))\n",
    "\n",
    "    #Q6. Which programming language is the second most popular among users who joined after 2020?\n",
    "\n",
    "    #Group by code\n",
    "    df_fltr = df[df['login'] == 'maddydevgits']\n",
    "    grouped_dft6 = df_fltr.groupby('language').size().reset_index(name='count')\n",
    "    df_sortedt6 = grouped_dft6.sort_values(by='count', ascending=False)\n",
    "\n",
    "    #Q14. Who created the most repositories on weekends (UTC)? List the top 5 users' login in order, comma-separated\n",
    "\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['day_of_week'] = df['created_at'].dt.dayofweek\n",
    "\n",
    "    df_fltr_14 = df[df['day_of_week'].isin([5,6])]\n",
    "    grouped_dft14 = df_fltr_14.groupby('login').size().reset_index(name='count')\n",
    "    df_sortedt14 = grouped_dft14.sort_values(by='count', ascending=False)\n",
    "    print(df_sortedt14)\n",
    "\n",
    "\n",
    "    #Q9. What is the correlation between the number of followers and the number of public repositories among users in Hyderabad?\n",
    "\n",
    "if response_users.status_code == 200:\n",
    "    # Read the CSV (Repos) content into a pandas DataFrame\n",
    "    csv_content = response_users.content.decode('utf-8')\n",
    "    df_users = pd.read_csv(StringIO(csv_content))\n",
    "    #print(df_users[['followers','count_of_repos']])\n",
    "\n",
    "    #Correlation between Followers and repos count:\n",
    "    #for col in df_users.columns:\n",
    "     # if 'followers' in col or 'count' in col:\n",
    "    correlation_coefficient = df_users['followers'].corr(df_users['count_of_repos'])\n",
    "\n",
    "    # Print the correlation coefficient\n",
    "    print(f\"Correlation coefficient between followers and total repositories: {correlation_coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1730045408464,
     "user": {
      "displayName": "Raji",
      "userId": "15359009113822535956"
     },
     "user_tz": 0
    },
    "id": "IUIycNg5ubsc",
    "outputId": "0eb1f01d-7ec7-4139-d89b-cf207399fa68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient between followers and public repositories among users in Hyderabad: 0.005667047286286638\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Q9. What is the correlation between the number of followers and the number of public repositories among users in Hyderabad?\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Step 4: Calculate the correlation between 'followers' and 'public_repos'\n",
    "correlation_coefficient = users_df['followers'].corr(users_df['public_repos'])\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(f\"Correlation coefficient between followers and public repositories among users in Hyderabad: {correlation_coefficient}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1730058248290,
     "user": {
      "displayName": "Raji",
      "userId": "15359009113822535956"
     },
     "user_tz": 0
    },
    "id": "0XvUeKAyvo9H",
    "outputId": "f9b15b7a-d828-48b3-a808-134abc59d097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(503, 1)\n",
      "(503,)\n",
      "0.06296441574945554\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "#Q10. Does creating more repos help users get more followers? Using regression, estimate how many additional followers a user gets per additional public repository.\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Step 4: Calculate the correlation between 'followers' and 'public_repos'\n",
    "x = users_df[['public_repos']].values\n",
    "y = users_df['followers'].values\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)\n",
    "\n",
    "print(model.coef_[0])\n",
    "\n",
    "#Slope = 0.06296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1730059941147,
     "user": {
      "displayName": "Raji",
      "userId": "15359009113822535956"
     },
     "user_tz": 0
    },
    "id": "L2oM-E3xi36I",
    "outputId": "96486aec-a79e-4332-e633-cc119c15d600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient between has_projects and has_wiki: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "#Q11. Do people typically enable projects and wikis together? What is the correlation between a repo having projects enabled and having wiki enabled?\n",
    "users_df_11 = pd.read_csv('repositories.csv')\n",
    "users_df_11 = users_df_11.dropna(subset=['has_projects', 'has_wiki'])\n",
    "\n",
    "# Step 4: Calculate the correlation between 'followers' and 'public_repos'\n",
    "users_df_11['has_projects'] = users_df_11['has_projects'].astype(int)\n",
    "users_df_11['has_wiki'] = users_df_11['has_wiki'].astype(int)\n",
    "\n",
    "# Print the correlation coefficient\n",
    "correlation_11 = users_df_11['has_projects'].corr(users_df_11['has_wiki'])\n",
    "print(f\"Correlation coefficient between has_projects and has_wiki: {correlation_11}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAAU4OHXm9YD"
   },
   "outputs": [],
   "source": [
    "from re import S\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "#Q12. Do hireable users follow more people than those who are not hireable?\n",
    "# Average of following per user for hireable=true minus the average following for the rest (to 3 decimal places, e.g. 12.345 or -12.345)\n",
    "url_users = \"https://raw.githubusercontent.com/Rajalakshmi12/IITM_Tds_Project1/main/users.csv\"\n",
    "response = requests.get(url_users)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Read the CSV (Repos) content into a pandas DataFrame\n",
    "    csv_content = response.content.decode('utf-8')\n",
    "    users_df = pd.read_csv(StringIO(csv_content))\n",
    "    users_df['hireable'] = users_df['hireable'].astype(bool)\n",
    "\n",
    "    users_dffilter12_q1 = users_df[users_df['hireable'] == True]\n",
    "    first_mean = users_dffilter12_q1['following'].mean()\n",
    "    print(round(first_mean,3))\n",
    "\n",
    "    users_dffilter12_q2 = users_df[users_df['hireable'] == False]\n",
    "    second_mean = users_dffilter12_q2['following'].mean()\n",
    "    print(round(second_mean,3))\n",
    "\n",
    "    average_difference = round(round(first_mean,3) - round(second_mean, 3),3)\n",
    "    print(average_difference)\n",
    "\n",
    "#Q15. Do people who are hireable share their email addresses more often?\n",
    "    #users_df = users_df.dropna(subset=['email'])\n",
    "    users_dffilter15_v1 = users_df[users_df['hireable'] == True]\n",
    "    users_dffilter15_v2 = users_df[users_df['hireable'] == False]\n",
    "\n",
    "    frac_hire = users_dffilter15_v1['email'].count()/users_dffilter15_v1.shape[0]\n",
    "    frac_non_hire = users_dffilter15_v2['email'].count()/users_dffilter15_v2.shape[0]\n",
    "    print(round(frac_hire,3))\n",
    "    print(round(frac_non_hire,3))\n",
    "    print(round(frac_hire - frac_non_hire,3))\n",
    "\n",
    "    #Q13. Some developers write long bios. Does that help them get more followers? What's the correlation of the length of their bio (in Unicode words, split by whitespace) with followers? (Ignore people without bios)\n",
    "    users_df = users_df.dropna(subset=['bio'])\n",
    "    users_df['bio_length'] = users_df['bio'].str.split().str.len()\n",
    "\n",
    "    x = users_df[['bio_length']].values\n",
    "    y = users_df['followers'].values\n",
    "    model = LinearRegression()\n",
    "    model.fit(x,y)\n",
    "    print(model.coef_[0])\n",
    "\n",
    "    #!16. Let's assume that the last word in a user's name is their surname (ignore missing names, trim and split by whitespace.) What's the most common surname? (If there's a tie, list them all, comma-separated, alphabetically)\n",
    "    users_df = users_df.dropna(subset=['name'])\n",
    "    users_df['surname'] = users_df['name'].str.split().str[-1]\n",
    "\n",
    "    grouped_16 = users_df.groupby('surname').size().reset_index(name='count')\n",
    "    df_sorted16 = grouped_16.sort_values(by='count', ascending=False)\n",
    "    print(df_sorted16)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOQtnf+rs2vfGUp64CKWGvP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
